![Python](https://img.shields.io/badge/Python-3.10.19%20-blue?logo=python)

| [ğŸ‡¬ğŸ‡§ Read in English](README_en.md) | [ğŸ‡®ğŸ‡¹ Leggi in Italiano](README.md) | 
| :--- | :--- |
## ğŸ“Š Il Dataset

Il dataset **PPG-DaLiA** (PPG-based Heart Rate Estimation Dataset for Daily Life Activities) Ã¨ stato creato per affrontare la sfida della stima della frequenza cardiaca tramite fotopletismografia (PPG) in presenza di artefatti da movimento. A differenza dei dataset di laboratorio, questo include registrazioni di lunga durata effettuate durante attivitÃ  di vita quotidiana.

### ğŸ“‚ Struttura delle Cartelle

Il dataset Ã¨ organizzato per soggetti. Esistono **15 soggetti** totali (7 uomini, 8 donne). Ogni soggetto ha la propria cartella identificata da un ID (es. `S1`, `S2`, ... `S15`).

```text
PPG-FieldStudy/
â”œâ”€â”€ S1/
â”‚   â”œâ”€â”€ S1.pkl           # Dati sincronizzati e pre-elaborati (Raccomandato)
â”‚   â”œâ”€â”€ S1_quest.csv     # Metadati del soggetto (etÃ , peso, fitness)
â”‚   â”œâ”€â”€ S1_activity.csv  # Timestamp di inizio delle attivitÃ 
â”‚   â”œâ”€â”€ S1_RespiBAN.h5   # Dati grezzi dal sensore toracico
â”‚   â””â”€â”€ S1_E4.zip        # Dati grezzi dal sensore al polso
â”œâ”€â”€ S2/
...
```
---

### ğŸ“„ Dettaglio dei File

#### 1. Il File Master: `SX.pkl` (Consigliato per il Machine Learning)

Questo file Ã¨ un dizionario Python (`pickle`) che contiene tutti i dati giÃ  **sincronizzati e pronti all'uso**. Ãˆ la risorsa principale se vuoi iniziare subito a addestrare modelli.

*  **`signal`**: Contiene i dati grezzi sincronizzati da entrambi i dispositivi:
    * `wrist`: Dati del sensore Empatica E4 (ACC, BVP, EDA, TEMP).
    * `chest`: Dati del sensore RespiBAN (ACC, ECG, RESP).
* **`label`**: La *Ground Truth* della frequenza cardiaca (calcolata dall'ECG) fornita per finestre di 8 secondi con uno shift di 2 secondi.
* **`activity`**: Etichette delle attivitÃ  corrispondenti ai dati.
*  **`questionnaire`**: Informazioni demografiche sul soggetto.
* **`rpeaks`**: Gli indici dei picchi R estratti dal segnale ECG.

#### 2. Dati dei Sensori (Raw Data)

Se preferisci lavorare con i dati non processati, sono disponibili due sorgenti:

*  **RespiBAN (Torace)**: Campionato a **700 Hz**. Include segnali ECG (usati per la veritÃ  di base), respirazione e accelerometro 3D .
* **Empatica E4 (Polso)**: Include diversi sensori con frequenze differenti:
    * **BVP (PPG)**: 64 Hz (Il segnale principale per la stima HR).
    * **ACC**: 32 Hz (3 assi, fondamentale per compensare il movimento).
    * **EDA / TEMP**: 4 Hz.

#### 3. Metadati e Protocollo: `SX_quest.csv` e `SX_activity.csv`

* **Metadati**: EtÃ , genere, altezza, peso, tipo di pelle (Fitzpatrick scale) e livello di fitness .

* **AttivitÃ **: Il dataset copre 8 attivitÃ  diverse svolte in condizioni naturali:


| ID | AttivitÃ  | Descrizione | Durata Media |
| --- | --- | --- | --- |
| 1 | Sitting | Seduti a leggere (baseline) | 10 min |
| 2 | Stairs | Salire e scendere 6 piani di scale | 5 min |
| 3 | Table Soccer | Partita a calcetto 1 vs 1 | 5 min |
| 4 | Cycling | Ciclismo all'aperto su vari terreni | 8 min |
| 5 | Driving | Guida in cittÃ  e su strade extraurbane | 15 min |
| 6 | Lunch Break | Coda in mensa, mangiare e parlare | 30 min |
| 7 | Walking | Camminata di ritorno in ufficio  | 10 min |
| 8 | Working | Lavoro al computer in ufficio | 20 min |
----

### âš ï¸ Note Importanti

*  **Soggetto S6**: A causa di un guasto hardware, i dati di S6 sono validi solo per i primi 90 minuti della raccolta.


*  **Sincronizzazione**: I dispositivi sono stati sincronizzati manualmente tramite un gesto di "doppio tocco" sul petto, registrato dagli accelerometri di entrambi i sensori.

Ecco una proposta per la sezione del file `README.md` che descrive la struttura del tuo progetto, integrando le informazioni tecniche del dataset **PPG-DaLiA**.

---

## ğŸ“‚ Struttura del Progetto

Il progetto Ã¨ organizzato in modo modulare per gestire le quattro fasi principali: pre-processing, fusione multimodale, generazione di segnali ECG e valutazione delle performance.

```text
PPG-ECG-Generation/
â”‚
â”œâ”€â”€ data/                       # Directory locale per la gestione dei dati
â”‚   â”œâ”€â”€ raw/                    # File originali del dataset SX.pkl (esclusi da git poichÃ© troppo grandi)
â”‚   â””â”€â”€ processed/              # Segnali memorizzati dopo la fase di pre-elaborazione
â”‚
â”œâ”€â”€ src/                        # Codice sorgente principale
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data_loader/            # Moduli per il caricamento dati e gestione Dataset PyTorch
â”‚   â”‚   â”œâ”€â”€ dalia_loader.py     # Caricamento dei file .pkl con dati sincronizzati e etichettati
â”‚   â”‚   â””â”€â”€ transforms.py       # Operazioni di normalizzazione e data augmentation
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/          # Fase 1: Elaborazione dei segnali canale per canale
â”‚   â”‚   â”œâ”€â”€ filters.py          # Implementazione di filtri passa-banda e rimozione artefatti
â”‚   â”‚   â””â”€â”€ segmentation.py     # Segmentazione tramite sliding window (8s di finestra, 2s di shift)
â”‚   â”‚
â”‚   â”œâ”€â”€ fusion/                 # Fase 2: Architettura di Fusione Multimodale
â”‚   â”‚   â”œâ”€â”€ attention.py        # Implementazione di meccanismi di Self e Cross-Attention
â”‚   â”‚   â””â”€â”€ fusion_layers.py    # Definizione della struttura di fusione (Early/Late/Hybrid)
â”‚   â”‚
â”‚   â”œâ”€â”€ generation/             # Fase 3: Definizione del Modello e Addestramento
â”‚   â”‚   â”œâ”€â”€ models/             # Architetture generative (es. GAN, Diffusion o UNet)
â”‚   â”‚   â”œâ”€â”€ trainer.py          # Gestione del loop di training e salvataggio dei pesi
â”‚   â”‚   â””â”€â”€ inference.py        # Generazione di ECG partendo da nuovi input PPG
â”‚   â”‚
â”‚   â””â”€â”€ evaluation/             # Fase 4: Metriche di Valutazione e Testing
â”‚       â”œâ”€â”€ metrics.py          # Calcolo di RMSE, correlazione e errore sulla HR
â”‚       â””â”€â”€ ablation.py         # Script per l'esecuzione di studi di ablazione
â”‚
â”œâ”€â”€ notebooks/                  # Jupyter Notebooks per analisi esplorativa e visualizzazioni
â”œâ”€â”€ configs/                    # File .yaml o .json per la gestione degli iperparametri
â”œâ”€â”€ scripts/                    # Script shell per avviare rapidamente addestramento o test
â”œâ”€â”€ tests/                      # Unit test per la validazione dei singoli moduli
â”œâ”€â”€ requirements.txt            # Dipendenze del progetto
â””â”€â”€ README.md                   # Documentazione principale

```

### Dettagli sui Componenti Core
_Da definire_